{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp abgeordnetenwatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Bundestag data from Abgeordnetenwatch\n",
    "> [Abgeordnetenwatch](https://www.abgeordnetenwatch.de) provides an [open API](https://www.abgeordnetenwatch.de/api) that provides info on, among other things, politicians, the politicians' votes and the different polls in parliament, including meta info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook collects the following information and prepares its parsing to `pandas.DataFrame` objects:\n",
    "* polls for the 2017-2021 period of the Bundestag\n",
    "* votes of members of the Bundestag 2017-2021\n",
    "* info on members of the Bundestag 2017-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOs:\n",
    "- identify why in vote json files some mandate_id values (politicians / mandates) appear multiple times (not always with the same vote result) -> affects `compile_votes_data` -> currently ignored and first of the duplicates used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "import requests, json\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "ABGEORDNETENWATCH_PATH = Path('../abgeordnetenwatch_data') # location for data storage\n",
    "API_ENCODING = 'ISO-8859-1'\n",
    "\n",
    "ABGEORDNETENWATCH_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level='INFO'); # default level for this module is INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry = True # set `True` for testing, `False` otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polls 2017-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polls = objects voted on in the Bundestag by the parlamentarians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_poll_info(legislature_id:int, dry=False):\n",
    "    \n",
    "    url = 'https://www.abgeordnetenwatch.de/api/v2/polls'\n",
    "    params = {\n",
    "        'field_legislature':legislature_id, #Bundestag period 2017-2021 = 111\n",
    "        'range_end':999, # setting a high limit to include all polls in one go    \n",
    "    }\n",
    "    \n",
    "    if dry:\n",
    "        logger.debug(f'Dry mode - request setup: url = {url}, params = {params}')\n",
    "        return\n",
    "    \n",
    "    r = requests.get(url, params=params)\n",
    "\n",
    "    logger.debug(f'Requested {r.url}')\n",
    "    assert r.status_code == 200, f'Unexpected GET status: {r.status_code}'\n",
    "\n",
    "    return r.json(encoding=API_ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislature_id = 111\n",
    "info = get_poll_info(legislature_id, dry=dry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def store_polls_json(polls:dict, legislature_id:int, dry=False):\n",
    "    polls_path = ABGEORDNETENWATCH_PATH / f'polls_legislature_{legislature_id}.json'\n",
    "    \n",
    "    if dry:\n",
    "        logger.debug(f'Dry mode - Writing poll info to {polls_path}')\n",
    "        return\n",
    "    logger.debug(f'Writing poll info to {polls_path}')\n",
    "    with open(polls_path, 'w', encoding='utf8') as f:\n",
    "        json.dump(info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_polls_json(info, legislature_id, dry=dry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_polls_json(legislature_id:int):\n",
    "    polls_path = ABGEORDNETENWATCH_PATH / f'polls_legislature_{legislature_id}.json'\n",
    "    logger.debug(f'Reading poll info from {polls_path}')\n",
    "    with open(polls_path, 'r', encoding='utf8') as f:\n",
    "        info = json.load(f)\n",
    "    return info\n",
    "\n",
    "def parse_poll_data(poll):\n",
    "\n",
    "    handle_committee = lambda x: None if x is None else None if len(x)==0 else x[0]['label']\n",
    "    handle_description = lambda x: BeautifulSoup(x, features=\"html.parser\").get_text().strip()\n",
    "    \n",
    "    d = {\n",
    "        'poll_id': poll['id'],\n",
    "        'poll_title': poll['label'],\n",
    "        'poll_first_committee': handle_committee(poll['field_committees']),\n",
    "        'poll_description': handle_description(poll['field_intro']), \n",
    "        'legislature_id': poll['field_legislature']['id'],\n",
    "        'legislature_period': poll['field_legislature']['label'],\n",
    "        'poll_date': poll['field_poll_date']\n",
    "    }\n",
    "    return d\n",
    "\n",
    "def test_poll_data(df:pd.DataFrame):\n",
    "    \"Basic sanity check on poll data\"\n",
    "    \n",
    "    # there should be no missing values except for poll_first_committee\n",
    "    for c in df.columns:\n",
    "        msg = f'{c}: failed because NaNs/None values were found.'\n",
    "        mask = df[c].isna()\n",
    "        if c == 'poll_first_committee': continue\n",
    "        assert mask.sum()==0, f'{msg}: \\n{df.loc[mask].head()}'\n",
    "        \n",
    "    # there should be no duplicated poll_id values\n",
    "    mask = df['poll_id'].duplicated()\n",
    "    assert mask.sum() == 0, f'Surprisingly found duplicated poll_id values: {df.loc[mask,\"poll_id\"].unique()} \\nexamples: \\n{df.loc[mask].head()}'\n",
    "\n",
    "def get_polls_df(legislature_id:int, test:bool=True):\n",
    "    \"Parses info from poll json files for `legislature_id`\"\n",
    "    info = load_polls_json(legislature_id)\n",
    "    df = pd.DataFrame([parse_poll_data(v) for v in info['data']])\n",
    "    if test:\n",
    "        test_poll_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "legislature_id = 111\n",
    "df = get_polls_df(legislature_id, test=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info on politicians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_mandates_info(legislature_id:int, dry=False):\n",
    "    url = f'https://www.abgeordnetenwatch.de/api/v2/candidacies-mandates'\n",
    "    params = {\n",
    "        'parliament_period':legislature_id, # collecting parlamentarians' votes\n",
    "        'range_end':999, # setting a high limit to include all mandates in one go\n",
    "    }\n",
    "    if dry:\n",
    "        logger.debug(f'Dry mode - request setup: url = {url}, params = {params}')\n",
    "        return\n",
    "    \n",
    "    r = requests.get(url, params=params)\n",
    "    logger.debug(f'Requested {r.url}')\n",
    "    assert r.status_code == 200, f'Unexpected GET status: {r.status_code}'\n",
    "\n",
    "    return r.json(encoding=API_ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislature_id = 111\n",
    "info = get_mandates_info(legislature_id,dry=dry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def store_mandates_info(mandates:dict, legislature_id:int, dry=False):\n",
    "    mandates_path = ABGEORDNETENWATCH_PATH / f'mandates_legislature_{legislature_id}.json'\n",
    "    \n",
    "    if dry:\n",
    "        logger.debug(f'Dry mode - Writing mandates info to {mandates_path}')\n",
    "        return\n",
    "    logger.debug(f'Writing mandates info to {mandates_path}')\n",
    "    with open(mandates_path, 'w', encoding='utf8') as f:\n",
    "        json.dump(mandates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_mandates_info(info, legislature_id, dry=dry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_mandate_json(legislature_id:int):\n",
    "    mandates_path = ABGEORDNETENWATCH_PATH / f'mandates_legislature_{legislature_id}.json'\n",
    "    logger.debug(f'Reading mandates info from {mandates_path}')\n",
    "    with open(mandates_path, 'r', encoding='utf8') as f:\n",
    "        info = json.load(f)\n",
    "    return info\n",
    "\n",
    "def parse_mandate_data(m):\n",
    "\n",
    "    handle_constituency = lambda x,k: x['electoral_data']['constituency'][k] if x['electoral_data'].get('constituency',None) else None\n",
    "    d = {\n",
    "        'legislature_id': m['parliament_period']['id'],\n",
    "        'legislature_period': m['parliament_period']['label'],\n",
    "        'mandate_id': m['id'],\n",
    "        'mandate': m['label'],\n",
    "        'politician_id': m['politician']['id'],\n",
    "        'politician': m['politician']['label'],\n",
    "        'politician_url': m['politician']['abgeordnetenwatch_url'],\n",
    "        'start_date': m['start_date'],\n",
    "        'end_date': m['end_date'],\n",
    "        'constituency_id': handle_constituency(m, 'id'), #  m['electoral_data']['constituency']['id']\n",
    "        'constituency_name': handle_constituency(m, 'label'), #m['electoral_data']['constituency']['label'],\n",
    "    }\n",
    "    if 'fraction_membership' in m:\n",
    "        d.update({\n",
    "            'fraction_names': [_m['label'] for _m in m['fraction_membership']],\n",
    "            'fraction_ids': [_m['id'] for _m in m['fraction_membership']],\n",
    "            'fraction_starts': [_m['valid_from'] for _m in m['fraction_membership']],\n",
    "            'fraction_ends': [_m['valid_until'] for _m in m['fraction_membership']],\n",
    "        })\n",
    "    return d\n",
    "\n",
    "def test_mandate_data(df:pd.DataFrame):\n",
    "    \"Basic sanity check on mandate data\"\n",
    "    \n",
    "    # there should be no missing values for any column in `cols`\n",
    "    cols = ['mandate_id', 'mandate', 'politician_id', 'politician']\n",
    "    for c in cols:\n",
    "        msg = f'{c}: failed because NaNs/None values were found.'\n",
    "        mask = df[c].isna()\n",
    "        assert mask.sum()==0, f'{msg}: \\n{df.loc[mask].head()}'\n",
    "        \n",
    "    # there should only be one id value for those columns in `cols` each\n",
    "    cols = ['legislature_id', 'legislature_period']\n",
    "    for c in cols:\n",
    "        ids = df[c].unique()\n",
    "        msg = f'Surprisingly found multiple {c} values: {ids}'\n",
    "        assert len(ids)==1, msg\n",
    "    \n",
    "    # there should be no duplicate mandate_id and politician_id values\n",
    "    cols = ['mandate_id', 'politician_id']\n",
    "    for c in cols:\n",
    "        mask = df[c].duplicated()\n",
    "        assert mask.sum() == 0, f'Surprisingly found duplicated {c} values: {df.loc[mask,c].unique()} \\nexamples: \\n{df.loc[mask].head()}'\n",
    "        \n",
    "def get_mandates_df(legislature_id:int, test:bool=True):\n",
    "    \"Parses info from mandate json file(s) for `legislature_id`\"\n",
    "    info = load_mandate_json(legislature_id)\n",
    "    df = pd.DataFrame([parse_mandate_data(v) for v in info['data']])\n",
    "    if test:\n",
    "        test_mandate_data(df)\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "legislature_id = 111\n",
    "df = get_mandates_df(legislature_id)\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Votes for one specific poll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_vote_info(poll_id:int, dry=False):\n",
    "        \n",
    "    url = f'https://www.abgeordnetenwatch.de/api/v2/polls/{poll_id}'\n",
    "    params = {\n",
    "        'related_data':'votes' # collecting parlamentarians' votes\n",
    "    }\n",
    "    if dry:\n",
    "        logger.debug(f'Dry mode - request setup: url = {url}, params = {params}')\n",
    "        return\n",
    "    \n",
    "    r = requests.get(url, params=params)\n",
    "\n",
    "    logger.debug(f'Requested {r.url}')\n",
    "    assert r.status_code == 200, f'Unexpected GET status: {r.status_code}'\n",
    "\n",
    "    return r.json(encoding=API_ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "poll_id = 4217\n",
    "info = get_vote_info(poll_id, dry=dry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def store_vote_info(votes:dict, poll_id:int, dry=False):\n",
    "    if dry:\n",
    "        logger.debug('Dry mode - Writing votes info ')\n",
    "        return\n",
    "    \n",
    "    legislature_id = votes['data']['field_legislature']['id']\n",
    "    votes_path = ABGEORDNETENWATCH_PATH / f'votes_legislature_{legislature_id}'\n",
    "    votes_path.mkdir(exist_ok=True)\n",
    "    votes_path = votes_path / f'poll_{poll_id}_votes.json'\n",
    "\n",
    "    logger.debug(f'Writing votes info to {votes_path}')\n",
    "    \n",
    "    with open(votes_path, 'w', encoding='utf8') as f:\n",
    "        json.dump(info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_vote_info(info, poll_id, dry=dry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_stored_vote_ids(legislature_id:int=None):\n",
    "    \n",
    "    dir2int = lambda x: int(str(x).split('_')[-1])\n",
    "    legislature_ids = {dir2int(v): v for v in ABGEORDNETENWATCH_PATH.glob('votes_legislature_*')}\n",
    "\n",
    "    file2int = lambda x: int(str(x).split('_')[-2])\n",
    "    id_unknown = legislature_id is not None and legislature_id not in legislature_ids\n",
    "    \n",
    "    if id_unknown:\n",
    "        logger.error(f'Given legislature_id {legislature_id} is unknown. Known ids: {sorted(list(legislature_ids.keys()))}')\n",
    "    \n",
    "    elif legislature_id is not None:\n",
    "        vote_ids = {file2int(v): v for v in (ABGEORDNETENWATCH_PATH/f'votes_legislature_{legislature_id}').glob('poll_*_votes.json')}\n",
    "        return {legislature_id: vote_ids}\n",
    "    \n",
    "    else:\n",
    "        all_ids = {}\n",
    "        for leg_id, leg_path in legislature_ids.items():\n",
    "            all_ids[leg_id] = {file2int(v): v for v in leg_path.glob('poll_*_votes.json')}\n",
    "        return all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tmp = check_stored_vote_ids()\n",
    "assert isinstance(tmp, dict), 'Sanity check for dict type of `tmp` failed'\n",
    "assert all([isinstance(v, dict) for v in tmp.values()]), 'Sanity check for dict type of values of `tmp` failed'\n",
    "assert all([isinstance(p, Path) for d in tmp.values() for p in d.values()]), 'Sanity check of lowest level values failed, expect all to be of type pathlib.Path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_vote_json(legislature_id:int, poll_id:int):\n",
    "    votes_path = ABGEORDNETENWATCH_PATH / f'votes_legislature_{legislature_id}/poll_{poll_id}_votes.json'\n",
    "    logger.debug(f'Reading vote info from {votes_path}')\n",
    "    with open(votes_path, 'r', encoding='utf8') as f:\n",
    "        info = json.load(f)\n",
    "    return info\n",
    "\n",
    "def parse_vote_data(vote):\n",
    "\n",
    "    d = {\n",
    "        'mandate_id': vote['mandate']['id'],\n",
    "        'mandate': vote['mandate']['label'],\n",
    "        'poll_id': vote['poll']['id'],\n",
    "        'vote': vote['vote'],\n",
    "        'reason_no_show': vote['reason_no_show'],\n",
    "        'reason_no_show_other': vote['reason_no_show_other'],\n",
    "    }\n",
    "    return d\n",
    "\n",
    "def test_vote_data(df):\n",
    "    \"Basic sanity check on vote data\"\n",
    "    \n",
    "    # there should be no missing values for any column in `cols`\n",
    "    cols = ['mandate_id', 'mandate', 'poll_id', 'vote']\n",
    "    for c in cols:\n",
    "        msg = f'{c}: failed because NaNs/None values were found.'\n",
    "        mask = df[c].isna()\n",
    "        assert mask.sum()==0, f'{msg}: \\n{df.loc[mask].head()}'\n",
    "        \n",
    "    # there should only be one poll_id value\n",
    "    ids = df['poll_id'].unique()\n",
    "    msg = f'Surprisingly found multiple poll_id values: {ids}'\n",
    "    assert len(ids)==1, msg\n",
    "    \n",
    "    # there should be no duplicate mandate_id value\n",
    "    mask = df['mandate_id'].duplicated()\n",
    "    assert mask.sum() == 0, f'Surprisingly found duplicated mandate_id values: {df.loc[mask,\"poll_id\"].unique()} \\nexamples: \\n{df.loc[mask].head()}'\n",
    "    \n",
    "def get_votes_df(legislature_id:int, poll_id:int, test:bool=True):\n",
    "    \"Parses info from vote json files for `legislature_id` and `poll_id`\"\n",
    "    info = load_vote_json(legislature_id, poll_id)\n",
    "    df = pd.DataFrame([parse_vote_data(v) for v in info['data']['related_data']['votes']])\n",
    "    if test:\n",
    "        test_vote_data(df)\n",
    "    return df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "legislature_id, poll_id = 111, 4217\n",
    "df = get_votes_df(legislature_id, poll_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All votes for all remaining polls of a specific legislative period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above only one specific poll vote information was collected for. Here we collect votes for whatever polls are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_all_remaining_vote_info(legislature_id:int, dry:bool=False,\n",
    "                                t_sleep:float=1, dt_rv_scale:float=.1, test:bool=True):\n",
    "    \"Loop through the remaining polls for `legislature_id` to collect all votes and write them to disk.\"\n",
    "    \n",
    "    # Get known legislature_id / poll_id combinations\n",
    "    known_id_combos = check_stored_vote_ids(legislature_id=legislature_id)\n",
    "\n",
    "    # Get polls info for legislative period\n",
    "    df_period = get_polls_df(legislature_id, test=test)\n",
    "    \n",
    "    # remaining poll ids to collect\n",
    "    remaining_poll_ids = [v for v in df_period['poll_id'].unique() \n",
    "                          if v not in known_id_combos[legislature_id]]\n",
    "    logger.debug(f'remaining poll_ids (legislature_id = {legislature_id}) = {len(remaining_poll_ids)}:\\n{remaining_poll_ids}')\n",
    "\n",
    "    dt_rv = stats.norm(scale=dt_rv_scale)\n",
    "\n",
    "    for i, poll_id in enumerate(tqdm(remaining_poll_ids, total=len(remaining_poll_ids),\n",
    "                                     desc='poll_id')):\n",
    "        _t = t_sleep + abs(dt_rv.rvs())\n",
    "        if not dry:\n",
    "            time.sleep(_t)\n",
    "        info = get_vote_info(poll_id, dry=dry)\n",
    "        store_vote_info(info, poll_id, dry=dry)\n",
    "    logger.debug(f'vote collection for legislature_id {legislature_id} complete (dry = {dry})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "legislature_id = 111\n",
    "get_all_remaining_vote_info(legislature_id, dry=dry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compile_votes_data(legislature_id:int):\n",
    "    \"Compiles the individual politicians' votes for a specific legislature period\"\n",
    "    \n",
    "    known_id_combos = check_stored_vote_ids(legislature_id=legislature_id)\n",
    "\n",
    "    # TODO: figure out why some mandate_id entries are duplicate in vote_json files\n",
    "\n",
    "    df_all_votes = []\n",
    "    for poll_id in tqdm(known_id_combos[legislature_id], total=len(known_id_combos[legislature_id]), desc='poll_id'):\n",
    "        df = get_votes_df(legislature_id, poll_id, test=False)\n",
    "        \n",
    "        ids = df.loc[df.duplicated(subset=['mandate_id']),'mandate_id'].unique()\n",
    "        if len(ids) > 0:\n",
    "            logger.warning(f'Dropping duplicates for mandate_ids ({ids}):\\n{df.loc[df[\"mandate_id\"].isin(ids)]}')\n",
    "            df = df.drop_duplicates(subset=['mandate_id'])\n",
    "        test_vote_data(df)\n",
    "        \n",
    "        df_all_votes.append(df)\n",
    "\n",
    "    return pd.concat(df_all_votes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "legislature_id = 111\n",
    "df_all_votes = compile_votes_data(legislature_id)\n",
    "\n",
    "display(df_all_votes.head(), df_all_votes.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write compiled votes to disk as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_votes_path = ABGEORDNETENWATCH_PATH / f'compiled_votes_legislature_{legislature_id}.parquet'\n",
    "df_all_votes.to_csv(all_votes_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head $all_votes_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_fastai]",
   "language": "python",
   "name": "conda-env-py38_fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "296px",
    "width": "456px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
