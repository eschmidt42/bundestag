{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Member similarity\n",
    "> Computing the similarity of members of the Bundestag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import typing\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing similarities between members of parliament based on their votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complicating factors:\n",
    "- not every parlamentarian voted for all the available issues\n",
    "- the union of issues voted on between parliamentarians may vary between all pairs of parliamentarian\n",
    "- similarity metric: cosine, agreement (# of same votes for all shared issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_parquet('../votes.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_squished_dataframe(df:pd.DataFrame, id_col:str='Bezeichnung',\n",
    "                                 feature_cols:typing.List[str]=['ja', 'nein', 'Enthaltung', 'ung√ºltig', 'nichtabgegeben'],\n",
    "                                 topic_cols:typing.List=['date', 'title']):\n",
    "\n",
    "    tmp = df.loc[:, [id_col]+feature_cols]\n",
    "    tmp['issue'] = df['date'].apply(str) + ' ' + df['title']\n",
    "\n",
    "    tmp = tmp.set_index([id_col, 'issue'])\n",
    "    return (tmp[tmp == 1].stack()\n",
    "            .reset_index()\n",
    "            .drop(0,1)\n",
    "            .rename(columns={'level_2':'vote'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_squished = get_squished_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_squished.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_agreements_painfully_slow(df:pd.DataFrame, \n",
    "                                  member0:str, member1:str, \n",
    "                                  verbose:bool=False,\n",
    "                                  id_col:str='Bezeichnung'):\n",
    "    #TODO: prettify & speed test the calculation\n",
    "    members = df[id_col].unique()\n",
    "    assert member0 in members, f'{member0} not found'\n",
    "    assert member1 in members, f'{member1} not found'\n",
    "    res = {}\n",
    "    \n",
    "    member0_mask = df[id_col] == member0\n",
    "    member1_mask = df[id_col] == member1\n",
    "    \n",
    "    common_issues = set(df.loc[member0_mask,'issue'].values).intersection(df.loc[member1_mask,'issue'].values)\n",
    "\n",
    "    common_issue_mask = df['issue'].isin(common_issues)\n",
    "    votes0 = df.loc[member0_mask & common_issue_mask].sort_values('issue')\n",
    "    votes1 = df.loc[member1_mask & common_issue_mask].sort_values('issue')\n",
    "    n_issues = df.loc[common_issue_mask,'issue'].nunique()\n",
    "    \n",
    "    if n_issues == 0:\n",
    "        return res\n",
    "    \n",
    "    agreement_frac = (votes0['vote'].values == votes1['vote'].values).sum() / n_issues\n",
    "    if verbose: print(f'overall agreement {agreement_frac*100:.2f} %')\n",
    "    \n",
    "    res['overall_frac'] = agreement_frac\n",
    "    res['overall_total'] = n_issues\n",
    "    res['member0'] = member0\n",
    "    res['member1'] = member1\n",
    "    \n",
    "    for outcome in df.loc[common_issue_mask,'vote'].unique():\n",
    "\n",
    "        n_issues = df.loc[common_issue_mask & (df['vote']==outcome), 'issue'].nunique()\n",
    "        issues0 = votes0.loc[votes0['vote']==outcome, 'issue'].unique()\n",
    "        issues1 = votes1.loc[votes1['vote']==outcome, 'issue'].unique()\n",
    "        n_agree = len(set(issues0).intersection(issues1))\n",
    "        agreement_frac = n_agree / n_issues\n",
    "        if verbose: print(f'\"{outcome}\" agreement {agreement_frac*100:.2f} %')\n",
    "        res[f'{outcome}_frac'] = agreement_frac\n",
    "        res[f'{outcome}_total'] = n_issues\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = df['Bezeichnung'].unique()\n",
    "num_members = len(members)\n",
    "members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member0 = 'Peter Altmaier'\n",
    "#member1 = 'Hubertus Heil (Peine)'\n",
    "member1 = 'Dr. Angela Merkel'\n",
    "assert member0 in members, f'{member0} not found'\n",
    "assert member1 in members, f'{member1} not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_agreements_painfully_slow(df_squished, member0, member1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_squished.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General agreement\n",
    "TODO: figure out how to do the relative ranking. one would need to count all the decisions which were the same as well as how many were different. the first part is a normal matrix product. the second part would be a matrix product with and \"or\" instead of the \"and\" condition of the normal matrix product. not sure how to do this yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dummy(df:pd.DataFrame, mask:pd.Series):\n",
    "    return (df.loc[mask]\n",
    "            .assign(dummy=True)\n",
    "            .pivot_table(index='Bezeichnung', columns='issue', values='dummy', fill_value=False)\n",
    "            .astype(bool))\n",
    "\n",
    "def scan_all_agreements(df:pd.DataFrame):\n",
    "    outcomes = df['vote'].unique()\n",
    "    agreements = {}\n",
    "    for outcome in tqdm.tqdm(outcomes, desc='Outcome', total=len(outcomes)):\n",
    "        mask = df['vote']==outcome\n",
    "        tmp = get_dummy(df, mask=mask)\n",
    "        members = tmp.index.values\n",
    "        similarity = 1 - pairwise_distances(tmp.values, metric='jaccard')\n",
    "        similarity = 100 * similarity\n",
    "        agreements[outcome] = pd.DataFrame(similarity, columns=members, index=members)\n",
    "    \n",
    "    tmp = get_dummy(df, df['vote'].notna()).astype(float)\n",
    "    members = tmp.index.values\n",
    "    tmp = np.dot(tmp.values, tmp.values.T)\n",
    "    agreements['total_shared_votes'] = pd.DataFrame(tmp, \n",
    "                                                    columns=members, \n",
    "                                                    index=members)\n",
    "    \n",
    "    return agreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "agreements = scan_all_agreements(df_squished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([v in agreements for v in df_squished['vote'].unique()])\n",
    "assert 'total_shared_votes' in agreements\n",
    "assert all([isinstance(v, pd.DataFrame) for v in agreements.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../similarities.pkl', 'wb') as f:\n",
    "    pickle.dump(agreements, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_web]",
   "language": "python",
   "name": "conda-env-py38_web-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
