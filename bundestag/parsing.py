# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_html_parsing.ipynb (unless otherwise specified).

__all__ = ['get_file_paths', 'collect_xlsx_uris', 'download_xlsx_file', 'download_multiple_xlsx_files', 'is_date',
           'get_xlsx_df', 'collect_xlsxs_as_dict']

# Cell
from bs4 import BeautifulSoup
from pathlib import Path
import re, os
import typing
import requests
import tqdm
import time
import pandas as pd
import itertools

# Cell
def get_file_paths(data_dir:typing.Union[Path,str], suffix:str=None, pattern=None):
    return list(set([data_dir/f for f in os.listdir(data_dir) if (suffix and f.endswith(suffix)) or (pattern and pattern.search(f))]))

# Cell
def collect_xlsx_uris(html_file_paths:typing.List[Path]):
    xlsx_uris = {}
    pattern = re.compile('(XLSX?)')

    for file_path in html_file_paths:

        with open(file_path, 'r') as f:
            soup = BeautifulSoup(f)

        elements = soup.find_all('td', attrs={'data-th':'Dokument'})
        for element in elements:
            title = element.div.p.strong.text.strip()
            href = element.find('a', attrs={'title':pattern})
            if href is None: continue
            xlsx_uris[title] = href['href']
    return xlsx_uris

# Cell
def download_xlsx_file(xlsx_uri:str, xlsx_dir:typing.Union[Path,str]=Path('../xlsx_data'),
                  verbose:bool=False):
    fname = xlsx_uri.split('/')[-1]
    xlsx_dir = Path(xlsx_dir)
    with open(xlsx_dir/fname, 'wb') as f:
        r = requests.get(xlsx_uri)
        if verbose: print(f'Writing to {xlsx_dir/fname}')
        f.write(r.content)

# Cell
def download_multiple_xlsx_files(xlsx_uris:typing.Dict[str,str], xlsx_dir:typing.Union[Path,str]=Path('../xlsx_data'),
                            t_sleep:float=.01):
    xlsx_file_title_maps = {}
    for xlsx_title, xlsx_uri in tqdm.tqdm(xlsx_uris.items(), desc='xlsx File', total=len(xlsx_uris)):
        download_xlsx_file(xlsx_uri, xlsx_dir=xlsx_dir)
        xlsx_file_title_maps[xlsx_uri.split('/')[-1]] = xlsx_title
        time.sleep(t_sleep)
    return xlsx_file_title_maps

# Cell
def is_date(s:str, fun:typing.Callable):
    try:
        _ = fun(s)
        return True
    except:
        return False

def get_xlsx_df(xlsx_file:typing.Union[str,Path], xlsx_file_title_maps:typing.Dict[str,str]=None):
    dfs = pd.read_excel(xlsx_file, sheet_name=None)
    assert len(dfs) == 1, 'The xlsx file has more than one page, that\' unexpected.'
    for name, df in dfs.items():
        df['sheet_name'] = name
        #df['date'] = pd.to_datetime(xlsx_file.name.split('_')[0])
    if xlsx_file_title_maps is not None:
        tmp = xlsx_file_title_maps[xlsx_file.name].split(':')
        date = tmp[0]
        if is_date(date, lambda x: pd.to_datetime(x, dayfirst=True)):
            date = pd.to_datetime(date, dayfirst=True)
            title = ':'.join(tmp[1:])
        elif is_date(xlsx_file.name.split('_')[0], pd.to_datetime):
            date = pd.to_datetime(xlsx_file.name.split('_')[0])
            title = xlsx_file_title_maps[xlsx_file.name]
        else:
            date = None
            title = xlsx_file_title_maps[xlsx_file.name]

        df['date'] = date
        df['title'] = title
    return df

# Cell
def collect_xlsxs_as_dict(xlsx_files:typing.List[typing.Union[Path,str]],
                          xlsx_file_title_maps:typing.Dict[str,str]=None):
    df = []
    for xlsx_file in xlsx_files:
        df.append(get_xlsx_df(xlsx_file, xlsx_file_title_maps=xlsx_file_title_maps))
    return pd.concat(df, ignore_index=True)